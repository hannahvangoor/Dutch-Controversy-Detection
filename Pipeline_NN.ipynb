{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Hannah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Hannah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for deep learning\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "## for bert language model\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "import re\n",
    "\n",
    "# Clean and tokenize text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords') # download stopwords corpus\n",
    "nltk.download('punkt') # download punkt tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Hannah/Documents/VU/Msc/Thesis/Coding/Pipeline\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/Hannah/Documents/VU/Msc/Thesis/Coding/Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('transformers_dataNew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['content'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shares</th>\n",
       "      <th>wow</th>\n",
       "      <th>cares</th>\n",
       "      <th>sad</th>\n",
       "      <th>angry</th>\n",
       "      <th>haha</th>\n",
       "      <th>reactions_count</th>\n",
       "      <th>comments</th>\n",
       "      <th>content</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RTL Nieuws</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Medewerkers van een aquarium in Spanje aten ge...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.776934</td>\n",
       "      <td>0.816872</td>\n",
       "      <td>0.773461</td>\n",
       "      <td>1.520865</td>\n",
       "      <td>1.432767</td>\n",
       "      <td>1.400064</td>\n",
       "      <td>0.703925</td>\n",
       "      <td>0.769034</td>\n",
       "      <td>1.060223</td>\n",
       "      <td>[ 2.12260270e+00  1.95452666e+00  6.88976407e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RTL Nieuws</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Er wordt wiet gerookt in het boek, gezoend, e...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.530748</td>\n",
       "      <td>1.590019</td>\n",
       "      <td>1.094324</td>\n",
       "      <td>1.871268</td>\n",
       "      <td>1.652691</td>\n",
       "      <td>1.231773</td>\n",
       "      <td>1.189072</td>\n",
       "      <td>1.068386</td>\n",
       "      <td>1.233858</td>\n",
       "      <td>[ 2.13255215e+00  1.18901312e+00  7.16963530e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RTL Nieuws</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>67</td>\n",
       "      <td>206</td>\n",
       "      <td>Andy en het team van de dragbar laten zich, on...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.372700</td>\n",
       "      <td>1.080609</td>\n",
       "      <td>0.964037</td>\n",
       "      <td>1.063937</td>\n",
       "      <td>1.858110</td>\n",
       "      <td>1.554261</td>\n",
       "      <td>0.934504</td>\n",
       "      <td>0.737435</td>\n",
       "      <td>1.404058</td>\n",
       "      <td>[ 2.12687016e+00  1.41113973e+00  9.98041630e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RTL Nieuws</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>Onder de slachtoffers waren volgens VN-mensenr...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.289650</td>\n",
       "      <td>1.249961</td>\n",
       "      <td>1.254739</td>\n",
       "      <td>1.537239</td>\n",
       "      <td>1.924307</td>\n",
       "      <td>1.640161</td>\n",
       "      <td>0.366889</td>\n",
       "      <td>0.969132</td>\n",
       "      <td>0.716310</td>\n",
       "      <td>[ 2.9026854   0.780339    1.11986625  1.063458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RTL Nieuws</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>284</td>\n",
       "      <td>Alleen al de afgelopen drie dagen kwamen meer ...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.318510</td>\n",
       "      <td>1.263664</td>\n",
       "      <td>0.760335</td>\n",
       "      <td>1.193509</td>\n",
       "      <td>1.659033</td>\n",
       "      <td>1.697025</td>\n",
       "      <td>1.157894</td>\n",
       "      <td>1.496184</td>\n",
       "      <td>1.604272</td>\n",
       "      <td>[ 1.75874364  0.47566167  1.14991474  0.760251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>103</td>\n",
       "      <td>169</td>\n",
       "      <td>Elke aardbewoner surft jaarlijks gemiddeld mee...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.060578</td>\n",
       "      <td>1.298744</td>\n",
       "      <td>0.832913</td>\n",
       "      <td>1.100882</td>\n",
       "      <td>1.712117</td>\n",
       "      <td>0.040602</td>\n",
       "      <td>0.658332</td>\n",
       "      <td>1.102006</td>\n",
       "      <td>1.012051</td>\n",
       "      <td>[ 2.00863171  1.04274106  0.94798875  0.684139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>De Nederlander en zijn team Red Bull hadden de...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.239983</td>\n",
       "      <td>0.822294</td>\n",
       "      <td>0.695602</td>\n",
       "      <td>1.593539</td>\n",
       "      <td>1.619219</td>\n",
       "      <td>1.291816</td>\n",
       "      <td>0.724189</td>\n",
       "      <td>0.918574</td>\n",
       "      <td>1.635511</td>\n",
       "      <td>[ 1.101861    1.73083413  0.7798183   0.473033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>„We weten weinig van de mogelijke effecten van...</td>\n",
       "      <td>...</td>\n",
       "      <td>12.788166</td>\n",
       "      <td>1.192427</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>1.040017</td>\n",
       "      <td>1.249091</td>\n",
       "      <td>1.165109</td>\n",
       "      <td>0.630857</td>\n",
       "      <td>1.169717</td>\n",
       "      <td>1.338238</td>\n",
       "      <td>[ 2.35046268  1.5198431   0.71057779  1.275846...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>91</td>\n",
       "      <td>135</td>\n",
       "      <td>Het rommelt binnen het CDA. De Telegraaf</td>\n",
       "      <td>...</td>\n",
       "      <td>12.757520</td>\n",
       "      <td>0.974428</td>\n",
       "      <td>0.540617</td>\n",
       "      <td>1.341013</td>\n",
       "      <td>1.987473</td>\n",
       "      <td>0.697544</td>\n",
       "      <td>0.471119</td>\n",
       "      <td>0.873903</td>\n",
       "      <td>1.283651</td>\n",
       "      <td>[ 2.13793945e+00  1.02813029e+00  3.28069597e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>De Telegraaf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>Balen! De Telegraaf</td>\n",
       "      <td>...</td>\n",
       "      <td>13.192951</td>\n",
       "      <td>1.297148</td>\n",
       "      <td>1.024886</td>\n",
       "      <td>1.223937</td>\n",
       "      <td>0.638661</td>\n",
       "      <td>1.344255</td>\n",
       "      <td>0.668650</td>\n",
       "      <td>0.120446</td>\n",
       "      <td>0.707811</td>\n",
       "      <td>[ 1.05763030e+00  1.12195158e+00  6.78173304e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9975 rows × 789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  shares  wow  cares  sad  angry  haha  reactions_count   \n",
       "0       RTL Nieuws       0   17      0    0      0    14               39  \\\n",
       "1       RTL Nieuws       0    1      0    0      0    10               15   \n",
       "2       RTL Nieuws       1    0     11    0      0    38               67   \n",
       "3       RTL Nieuws       2    4      7   19      0     0               30   \n",
       "4       RTL Nieuws       5   12      0    0      0    21               58   \n",
       "...            ...     ...  ...    ...  ...    ...   ...              ...   \n",
       "9995  De Telegraaf       3    0      0    0      0    47              103   \n",
       "9996  De Telegraaf       4    0      0    0      0    17               60   \n",
       "9997  De Telegraaf       2    0      0    0     23    39               71   \n",
       "9998  De Telegraaf       3    0      0    0      0    60               91   \n",
       "9999  De Telegraaf       0    0      0   32      0    21              115   \n",
       "\n",
       "      comments                                            content  ...   \n",
       "0            0  Medewerkers van een aquarium in Spanje aten ge...  ...  \\\n",
       "1            0  \"Er wordt wiet gerookt in het boek, gezoend, e...  ...   \n",
       "2          206  Andy en het team van de dragbar laten zich, on...  ...   \n",
       "3           26  Onder de slachtoffers waren volgens VN-mensenr...  ...   \n",
       "4          284  Alleen al de afgelopen drie dagen kwamen meer ...  ...   \n",
       "...        ...                                                ...  ...   \n",
       "9995       169  Elke aardbewoner surft jaarlijks gemiddeld mee...  ...   \n",
       "9996        26  De Nederlander en zijn team Red Bull hadden de...  ...   \n",
       "9997        65  „We weten weinig van de mogelijke effecten van...  ...   \n",
       "9998       135           Het rommelt binnen het CDA. De Telegraaf  ...   \n",
       "9999         0                                Balen! De Telegraaf  ...   \n",
       "\n",
       "     embedding_759 embedding_760  embedding_761  embedding_762  embedding_763   \n",
       "0        13.776934      0.816872       0.773461       1.520865       1.432767  \\\n",
       "1        13.530748      1.590019       1.094324       1.871268       1.652691   \n",
       "2        13.372700      1.080609       0.964037       1.063937       1.858110   \n",
       "3        13.289650      1.249961       1.254739       1.537239       1.924307   \n",
       "4        13.318510      1.263664       0.760335       1.193509       1.659033   \n",
       "...            ...           ...            ...            ...            ...   \n",
       "9995     13.060578      1.298744       0.832913       1.100882       1.712117   \n",
       "9996     13.239983      0.822294       0.695602       1.593539       1.619219   \n",
       "9997     12.788166      1.192427       0.812722       1.040017       1.249091   \n",
       "9998     12.757520      0.974428       0.540617       1.341013       1.987473   \n",
       "9999     13.192951      1.297148       1.024886       1.223937       0.638661   \n",
       "\n",
       "      embedding_764  embedding_765  embedding_766  embedding_767   \n",
       "0          1.400064       0.703925       0.769034       1.060223  \\\n",
       "1          1.231773       1.189072       1.068386       1.233858   \n",
       "2          1.554261       0.934504       0.737435       1.404058   \n",
       "3          1.640161       0.366889       0.969132       0.716310   \n",
       "4          1.697025       1.157894       1.496184       1.604272   \n",
       "...             ...            ...            ...            ...   \n",
       "9995       0.040602       0.658332       1.102006       1.012051   \n",
       "9996       1.291816       0.724189       0.918574       1.635511   \n",
       "9997       1.165109       0.630857       1.169717       1.338238   \n",
       "9998       0.697544       0.471119       0.873903       1.283651   \n",
       "9999       1.344255       0.668650       0.120446       0.707811   \n",
       "\n",
       "                                             embeddings  \n",
       "0     [ 2.12260270e+00  1.95452666e+00  6.88976407e-...  \n",
       "1     [ 2.13255215e+00  1.18901312e+00  7.16963530e-...  \n",
       "2     [ 2.12687016e+00  1.41113973e+00  9.98041630e-...  \n",
       "3     [ 2.9026854   0.780339    1.11986625  1.063458...  \n",
       "4     [ 1.75874364  0.47566167  1.14991474  0.760251...  \n",
       "...                                                 ...  \n",
       "9995  [ 2.00863171  1.04274106  0.94798875  0.684139...  \n",
       "9996  [ 1.101861    1.73083413  0.7798183   0.473033...  \n",
       "9997  [ 2.35046268  1.5198431   0.71057779  1.275846...  \n",
       "9998  [ 2.13793945e+00  1.02813029e+00  3.28069597e-...  \n",
       "9999  [ 1.05763030e+00  1.12195158e+00  6.78173304e-...  \n",
       "\n",
       "[9975 rows x 789 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  109137408   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 768)         0           ['tf_bert_model_2[0][0]']        \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          98432       ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)          (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 64)           8256        ['dropout_117[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_118 (Dropout)          (None, 64)           0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 32)           2080        ['dropout_118[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)          (None, 32)           0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            33          ['dropout_119[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,246,209\n",
      "Trainable params: 108,801\n",
      "Non-trainable params: 109,137,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 10:01:34.932788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype double and shape [6982]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "/opt/anaconda3/envs/modelenv/lib/python3.11/site-packages/keras/engine/functional.py:639: UserWarning: Input dict contained keys ['token_type_ids'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "2023-06-05 10:21:38.107053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype double and shape [1496]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-06-05 12:21:08.663579: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype double and shape [1497]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 190s 4s/step\n",
      "Mean Squared Error: 0.14353211991459983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('Indicator-Desc_DataNew.csv')\n",
    "df.dropna(subset=['content'], inplace=True)\n",
    "X = df['content']\n",
    "y = df['entropy']\n",
    "\n",
    "# split train dataset into train, validation and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, random_state=2018, test_size=0.3)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, random_state=2018, test_size=0.5)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X , y, train_size=0.8)\n",
    "\n",
    "# BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "\n",
    "# Tokenize and encode the text data\n",
    "train_tokens = tokenizer.batch_encode_plus(\n",
    "    X_train.values.tolist(),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "# Tokenize and encode the text data\n",
    "val_tokens = tokenizer.batch_encode_plus(\n",
    "    X_val.values.tolist(),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "test_tokens = tokenizer.batch_encode_plus(\n",
    "    X_test.values.tolist(),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "# Convert the tokenized input to TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_tokens),\n",
    "    y_train.values\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_tokens),\n",
    "    y_val.values\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_tokens),\n",
    "    y_test.values\n",
    "))\n",
    "\n",
    "# Prepare the model input\n",
    "input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "# Load BERT model\n",
    "model = TFAutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # Tensorflow\n",
    "\n",
    "# Freeze BERT layers\n",
    "model.trainable = False\n",
    "\n",
    "# Retrieve the BERT embeddings\n",
    "embeddings = model(input_ids,attention_mask)[0]\n",
    "\n",
    "# Perform pooling (average pooling in this case)\n",
    "pooled_output = tf.keras.layers.GlobalAveragePooling1D()(embeddings)\n",
    "\n",
    "# Intermediate dense layers with ReLU activation and dropout\n",
    "hidden_units = [128, 64, 32]\n",
    "dropout_rate = 0.2\n",
    "\n",
    "for units in hidden_units:\n",
    "    pooled_output = tf.keras.layers.Dense(units, activation='relu')(pooled_output)\n",
    "    pooled_output = tf.keras.layers.Dropout(dropout_rate)(pooled_output)\n",
    "\n",
    "# Dense layer for regression output\n",
    "output = tf.keras.layers.Dense(1, activation='linear')(pooled_output)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# Compile the model, learning rate: 1e-4\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4), loss='mean_squared_error')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "training = model.fit(train_dataset.batch(256), epochs=5, shuffle=True, verbose=0, validation_data=val_dataset.batch(256))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = model.predict(test_dataset.batch(32))\n",
    "mse = mean_squared_error(y_test.values, predictions)\n",
    "print('Mean Squared Error:', mse)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794, Language model approach\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
